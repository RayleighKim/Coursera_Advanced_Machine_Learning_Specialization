{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w12_Quiz_Overfitting_and_regularization",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/RayleighKim/Coursera_Advanced_Machine_Learning_Specialization/blob/master/01_Introduction_To_DeepLearning/w12_Quiz_Overfitting_and_regularization.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "M5urgouueCxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Quiz : Overfitting and regularization\n",
        "---\n",
        "Rayleigh Kim @ dplus\n",
        "\n",
        "email1 : rayleigh@dplus.company<br>\n",
        "email2 : wood.rayleigh@gmail.com\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GdSYY0wXfDYc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q1. Select correct statements about overfitting\n",
        "\n",
        "* Large model weights can indicate that model is overfitted : **TRUE, that's why we sometimes use regularization**\n",
        "* Overfitting happens when modle is too simple for the problem : **FALSE, Underfitting may happens.**\n",
        "* Overfitting is a situation where a model gives lower quality for new data compared to quality on a training sample : **TRUE, which means that we can't use our model generally.**\n",
        "* Overfitting is a situation where a model gives comparable quality on new data and on a training sample : **FALSE. we just find the model which not violate reproducibility.**\n"
      ]
    },
    {
      "metadata": {
        "id": "uHRj09wzoUj3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q2. What disadvantages do model validation on holdout sample have?\n",
        "\n",
        "* It is sensitive to the particular split of the sample into training and test parts : **TRUE, so we use cross validation**\n",
        "* It can give biased quality estimates for small samples **TRUE**\n",
        "* It requires multiple model fitting **False, It is the disadvantage k-fold cross validation have**"
      ]
    },
    {
      "metadata": {
        "id": "z_IX-i9eo7hC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3. Suppose you are using k-fold cross-validation to assess model quality. How many times should you train the model during this procedure?\n",
        "\n",
        "* 1\n",
        "* k\n",
        "* k(k-1)/2\n",
        "* k^2\n",
        "\n",
        "hint : (  )-fold cross-validation"
      ]
    },
    {
      "metadata": {
        "id": "3kjXYMCIqD_n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q4. Select correct statements about regularization\n",
        "\n",
        "* Weight penalty reduces the number of model parameters and leads to faster model training : **FALSE, can't reduce, it just drives model parameters smaller**\n",
        "* Weight penalty drives model parameters colser to zero and prevents the model from being too sensitive to small changes in features : **TRUE**\n",
        "* Regularization restricts model compexity (namely the scale of the coefficients) to reduce overfitting : **TRUE**\n",
        "* Reducing the training sample size makes data simpler and then leads to better quality : **FALSE,  why.. why big data why..**\n"
      ]
    },
    {
      "metadata": {
        "id": "d09MLDNCr8QT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}