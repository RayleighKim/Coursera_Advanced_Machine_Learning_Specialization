{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w31_Quiz_Convolutions_and_pooling",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/RayleighKim/Coursera_Advanced_Machine_Learning_Specialization/blob/master/01_Introduction_To_DeepLearning/w31_Quiz_Convolutions_and_pooling.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "M5urgouueCxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Quiz : Convolutions and Pooling\n",
        "---\n",
        "Rayleigh Kim @ dplus\n",
        "\n",
        "email1 : rayleigh@dplus.company<br>\n",
        "email2 : wood.rayleigh@gmail.com\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GdSYY0wXfDYc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q1. Choose correct statements about convolutional layer:\n",
        "\n",
        "* Convolutional layer provides translation invariance : **False, [transalation equivariant] **\n",
        "* Convolutional layer is a special case of a fully-connected layer **True, I think that Convolutional layer is a locally-connected,  not a fully-connected layer, but if a fully-connected layer has shared weights and 0 weights outside local receptive field... **\n",
        "* Convolutional layer works the same way for every input patch **True, a Convolutional layer used same weights.**\n",
        "* Convolutional layer doesn't need a bias term **False, need a bias term**"
      ]
    },
    {
      "metadata": {
        "id": "NNzc6I1mg2eg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q2. Choose correct statements about pooling layer:\n",
        "* Pooling layer is strictly differentiable **False, Max pooling layer is not differentiable**\n",
        "* Pooling layer provides translation invariance **True, Pooling layer will help maintain translation invariance**\n",
        "* Pooling layer can reduce spatial dimensions (width and heights of the input volume) **True, one of the main jobs(!) of pooling layer is to reduce spatial dimensions**\n",
        "* Pooling layer reduces the number of convolutional filters **False, pooling layer reduces the spatial dimensions, but not the number of filters**"
      ]
    },
    {
      "metadata": {
        "id": "mldNyHxdfisT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3. Back-propagation for convolutional layer first calculates the gradients as if the kernel parameters were not shared and then...\n",
        "\n",
        "* Takes a maximum gradient for each shared parameter \n",
        "* Takes a mean of the gradients for each shared parameter\n",
        "* Takes a sum of gradients for each shared parameter **True**\n",
        "* Takes a minimum gradient for each shared parameter\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CsW6lqlcffbJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q4. Suppose you have a 10x10x3 colour image input and want to stack two convolutional layers with kernel size 3x3 with 10 and 20 filters respectively. How many parameters do you have to train for these two layers? Don't forget bias terms! ~~how kind~~"
      ]
    },
    {
      "metadata": {
        "id": "h41oM-U0xvMk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "463d4677-8013-43b5-d94f-a2ece5935bd5"
      },
      "cell_type": "code",
      "source": [
        "## the N of parameters for first convolutional layer.\n",
        "first_kernel_size = 3*3\n",
        "image_ch = 3\n",
        "N_first_filters = 10\n",
        "N_first_params = (first_kernel_size*image_ch + 1)*N_first_filters\n",
        "\n",
        "print('the number of parameters for first convolutional layer is : {}'.format(N_first_params))\n",
        "\n",
        "## the N of parameters for second convolutional layer.\n",
        "second_kernel_size = 3*3 # same\n",
        "N_second_filters = 20\n",
        "N_second_params = (second_kernel_size*N_first_filters + 1)*N_second_filters\n",
        "\n",
        "print('the number of parameters for second convolutional layer is : {}'.format(N_second_params))\n",
        "\n",
        "print('The answer is {}'.format(N_first_params + N_second_params))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of parameters for first convolutional layer is : 280\n",
            "the number of parameters for second convolutional layer is : 1820\n",
            "The answer is 2100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ErhNqU7tzdRa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q5. What receptive field do we have after stacking n convolutional layers with kernel size $$k\\times k$$ and stride1? Layers numeration starts with 1. The resulting receptive field will be a square, input its side as an answer.\n",
        "\n",
        "<br>\n",
        "\n",
        "neurons of 1st Convolutional layer have receptive field of size : $$k \\times k $$\n",
        "\n",
        "neurons of 2nd Convolutional layer have receptive field of size : $$ [k+(k-1)] \\times [k+(k-1)] $$\n",
        "\n",
        "$$ \\dots $$\n",
        "\n",
        "neurons of n th Convolutional layer have receptive field of size : $$ [k+(n-1)\\times(k-1)] \\times [k+(n-1)\\times(k-1)] $$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KlU7djgsymxj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}